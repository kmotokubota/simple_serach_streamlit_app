# =========================================================
# Snowflakeãƒ‡ãƒ¼ã‚¿æ“ä½œã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
# ãƒ‡ãƒ¼ã‚¿å–è¾¼ãƒšãƒ¼ã‚¸
# =========================================================
# Created by kdaigo
# æœ€çµ‚æ›´æ–°: 2025/09/24
# =========================================================
import streamlit as st
import pandas as pd
import time
import io
from datetime import datetime
from snowflake.snowpark.context import get_active_session
from snowflake.snowpark.types import *
from snowflake.snowpark.functions import col

st.set_page_config(layout="wide", page_title="ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å–è¾¼", page_icon="ğŸ“¥")

@st.cache_resource
def get_snowflake_session():
    return get_active_session()

session = get_snowflake_session()

# =========================================================
# DB/ã‚¹ã‚­ãƒ¼ãƒå‹•çš„é¸æŠã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# =========================================================
@st.cache_data(ttl=60, show_spinner=False)
def get_available_databases():
    """ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—"""
    try:
        result = session.sql("SHOW DATABASES").collect()
        excluded_dbs = {'SNOWFLAKE', 'SNOWFLAKE_SAMPLE_DATA'}
        return sorted([row['name'] for row in result if row['name'] not in excluded_dbs])
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []

@st.cache_data(ttl=60, show_spinner=False)
def get_available_schemas(database_name: str):
    """æŒ‡å®šDBã®ã‚¹ã‚­ãƒ¼ãƒä¸€è¦§ã‚’å–å¾—"""
    if not database_name:
        return []
    try:
        result = session.sql(f"SHOW SCHEMAS IN DATABASE {database_name}").collect()
        excluded_schemas = {'INFORMATION_SCHEMA'}
        return sorted([row['name'] for row in result if row['name'] not in excluded_schemas])
    except Exception as e:
        st.error(f"ã‚¹ã‚­ãƒ¼ãƒå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []

def get_current_data_schema():
    """ç¾åœ¨é¸æŠã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—ï¼ˆDB.SCHEMAå½¢å¼ï¼‰"""
    if st.session_state.get('selected_database') and st.session_state.get('selected_schema'):
        return f"{st.session_state.selected_database}.{st.session_state.selected_schema}"
    return "application_db.application_schema"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'uploaded_files' not in st.session_state:
    st.session_state.uploaded_files = []
if 'import_scripts' not in st.session_state:
    st.session_state.import_scripts = []
if 'current_df' not in st.session_state:
    st.session_state.current_df = None
if 'inferred_schema' not in st.session_state:
    st.session_state.inferred_schema = []
if 'table_name' not in st.session_state:
    st.session_state.table_name = ""

# DB/ã‚¹ã‚­ãƒ¼ãƒé¸æŠã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
if 'selected_database' not in st.session_state:
    st.session_state.selected_database = ""
if 'selected_schema' not in st.session_state:
    st.session_state.selected_schema = ""

def check_table_exists(table_name: str) -> bool:
    """ãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ç¢ºèªï¼ˆé¸æŠã•ã‚ŒãŸã‚¹ã‚­ãƒ¼ãƒå†…ã§ç¢ºèªï¼‰"""
    try:
        current_schema = get_current_data_schema()
        result = session.sql(f"SHOW TABLES LIKE '{table_name}' IN {current_schema}").collect()
        return len(result) > 0
    except:
        return False

def infer_schema(df: pd.DataFrame) -> list:
    """CSVãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚¹ã‚­ãƒ¼ãƒã‚’æ¨æ¸¬ã™ã‚‹"""
    schema = []
    for col_name in df.columns:
        col_data = df[col_name]
        
        # ãƒ‡ãƒ¼ã‚¿å‹ã‚’æ¨æ¸¬
        if col_data.dtype == 'object':
            # æ–‡å­—åˆ—å‹ã®å ´åˆã€ãƒ•ãƒ«æ¡ã®VARCHARã‚’ä½¿ç”¨
            data_type = "VARCHAR(16777216)"  # Snowflakeã®æœ€å¤§VARCHARé•·
        elif col_data.dtype in ['int64', 'int32']:
            data_type = "NUMBER"
        elif col_data.dtype in ['float64', 'float32']:
            data_type = "FLOAT"
        elif col_data.dtype == 'bool':
            data_type = "BOOLEAN"
        elif pd.api.types.is_datetime64_any_dtype(col_data):
            data_type = "DATE"
        else:
            data_type = "VARCHAR(16777216)"
        
        schema.append({
            'column_name': col_name,
            'data_type': data_type,
            'sample_data': str(col_data.iloc[0]) if len(col_data) > 0 else ""
        })
    
    return schema

def create_table_sql(table_name: str, schema: list) -> str:
    """CREATE TABLEæ–‡ã‚’ç”Ÿæˆã™ã‚‹"""
    columns = []
    for col in schema:
        # ã‚«ãƒ©ãƒ åã‚’ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã§å›²ã¿ã€ãƒ‡ãƒ¼ã‚¿å‹ã¯ãã®ã¾ã¾ä½¿ç”¨
        column_def = f'"{col["column_name"]}" {col["data_type"]}'
        columns.append(column_def)
    
    # é¸æŠã•ã‚ŒãŸã‚¹ã‚­ãƒ¼ãƒã«ä½œæˆ
    current_schema = get_current_data_schema()
    full_table_name = f"{current_schema}.{table_name}"
    sql = f"CREATE OR REPLACE TABLE {full_table_name} (\n"
    sql += ",\n".join([f"    {col}" for col in columns])
    sql += "\n)"
    
    return sql

# =========================================================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼: DB/ã‚¹ã‚­ãƒ¼ãƒé¸æŠ
# =========================================================
st.sidebar.header("ğŸ—„ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é¸æŠ")

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é¸æŠ
databases = get_available_databases()
if databases:
    current_db = st.session_state.selected_database
    if current_db not in databases:
        current_db = databases[0] if databases else ""
    
    selected_db = st.sidebar.selectbox(
        "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹",
        databases,
        index=databases.index(current_db) if current_db in databases else 0,
        key="ingest_db_select"
    )
    
    if selected_db != st.session_state.selected_database:
        st.session_state.selected_database = selected_db
        st.session_state.selected_schema = ""
        st.rerun()
    
    # ã‚¹ã‚­ãƒ¼ãƒé¸æŠ
    schemas = get_available_schemas(st.session_state.selected_database)
    if schemas:
        current_schema = st.session_state.selected_schema
        if current_schema not in schemas:
            current_schema = schemas[0] if schemas else ""
        
        selected_schema = st.sidebar.selectbox(
            "ã‚¹ã‚­ãƒ¼ãƒ",
            schemas,
            index=schemas.index(current_schema) if current_schema in schemas else 0,
            key="ingest_schema_select"
        )
        if selected_schema != st.session_state.selected_schema:
            st.session_state.selected_schema = selected_schema
            st.rerun()
    else:
        st.sidebar.info("ã‚¹ã‚­ãƒ¼ãƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
else:
    st.sidebar.warning("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# é¸æŠä¸­ã®æƒ…å ±ã‚’è¡¨ç¤º
if st.session_state.selected_database and st.session_state.selected_schema:
    st.sidebar.success(f"ğŸ“ ä¿å­˜å…ˆ: {st.session_state.selected_database}.{st.session_state.selected_schema}")

st.sidebar.markdown("---")

st.title("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å–è¾¼")
st.header("CSVã€Excelã€å›ºå®šé•·ãƒ•ã‚¡ã‚¤ãƒ«ã®å–è¾¼ã¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆç®¡ç†")

# ãƒ¡ã‚¤ãƒ³æ©Ÿèƒ½
st.subheader("ğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
st.info("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€ã‚¹ã‚­ãƒ¼ãƒã‚’æ¨æ¸¬ãƒ»ç·¨é›†å¾Œã«Snowflakeãƒ†ãƒ¼ãƒ–ãƒ«ã¨ã—ã¦ä¿å­˜ã—ã¾ã™")

# Step 1: ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„", type=['csv'])

if uploaded_file is not None:
    try:
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        df = pd.read_csv(uploaded_file)
        st.session_state.current_df = df
        
        st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {uploaded_file.name}")
        st.write(f"**è¡Œæ•°**: {len(df):,} è¡Œ, **åˆ—æ•°**: {len(df.columns)} åˆ—")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        with st.expander("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=True):
            st.dataframe(df.head(10), use_container_width=True)
        
        # Step 2: ãƒ†ãƒ¼ãƒ–ãƒ«åå…¥åŠ›
        st.subheader("ğŸ·ï¸ ãƒ†ãƒ¼ãƒ–ãƒ«åã®è¨­å®š")
        default_table_name = f"IMPORT_{uploaded_file.name.split('.')[0].upper().replace('-', '_').replace(' ', '_')}"
        table_name = st.text_input(
            "ãƒ†ãƒ¼ãƒ–ãƒ«åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", 
            value=default_table_name,
            help="è‹±æ•°å­—ã¨ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã®ã¿ä½¿ç”¨å¯èƒ½ã§ã™"
        )
        st.session_state.table_name = table_name
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«åã®æ¤œè¨¼
        if table_name:
            if check_table_exists(table_name):
                st.warning(f"âš ï¸ ãƒ†ãƒ¼ãƒ–ãƒ« '{table_name}' ã¯é¸æŠä¸­ã®ã‚¹ã‚­ãƒ¼ãƒã«æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚ä¿å­˜æ™‚ã«ä¸Šæ›¸ãã•ã‚Œã¾ã™ã€‚")
        
        # Step 3: ã‚¹ã‚­ãƒ¼ãƒæ¨æ¸¬ã¨ç·¨é›†
        if table_name:
            st.subheader("ğŸ” ã‚¹ã‚­ãƒ¼ãƒç·¨é›†")
            
            # ã‚¹ã‚­ãƒ¼ãƒæ¨æ¸¬ãƒœã‚¿ãƒ³
            if st.button("ğŸ”„ ã‚¹ã‚­ãƒ¼ãƒã‚’æ¨æ¸¬", type="secondary"):
                st.session_state.inferred_schema = infer_schema(df)
                st.success("ã‚¹ã‚­ãƒ¼ãƒã‚’æ¨æ¸¬ã—ã¾ã—ãŸï¼")
            
            # ã‚¹ã‚­ãƒ¼ãƒãŒæ¨æ¸¬ã•ã‚Œã¦ã„ã‚‹å ´åˆã€ç·¨é›†å¯èƒ½ãªè¡¨ç¤º
            if st.session_state.inferred_schema:
                st.write("**æ¨æ¸¬ã•ã‚ŒãŸã‚¹ã‚­ãƒ¼ãƒï¼ˆç·¨é›†å¯èƒ½ï¼‰:**")
                
                # ãƒ‡ãƒ¼ã‚¿å‹ã®é¸æŠè‚¢
                data_type_options = [
                    "VARCHAR(16777216)",
                    "NUMBER", "FLOAT", "BOOLEAN", "DATE", "TIMESTAMP"
                ]
                
                # ã‚¹ã‚­ãƒ¼ãƒç·¨é›†ç”¨ã®ã‚³ãƒ³ãƒ†ãƒŠ
                schema_container = st.container()
                
                with schema_container:
                    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
                    col1, col2, col3, col4 = st.columns([3, 3, 2, 2])
                    with col1:
                        st.write("**åˆ—å**")
                    with col2:
                        st.write("**ãƒ‡ãƒ¼ã‚¿å‹**")
                    with col3:
                        st.write("**ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿**")
                    with col4:
                        st.write("**ã‚¨ãƒ©ãƒ¼**")
                    
                    # å„åˆ—ã®ã‚¹ã‚­ãƒ¼ãƒã‚’ç·¨é›†å¯èƒ½ã«ã™ã‚‹
                    updated_schema = []
                    for i, schema_item in enumerate(st.session_state.inferred_schema):
                        col1, col2, col3, col4 = st.columns([3, 3, 2, 2])
                        
                        with col1:
                            column_name = st.text_input(
                                f"åˆ—å_{i}", 
                                value=schema_item['column_name'],
                                key=f"col_name_{i}",
                                label_visibility="collapsed"
                            )
                        
                        with col2:
                            # ãƒ‡ãƒ¼ã‚¿å‹ã®é¸æŠè‚¢ã§ç¾åœ¨ã®å€¤ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                            current_data_type = schema_item['data_type']
                            if current_data_type not in data_type_options:
                                # å¤ã„å½¢å¼ã®VARCHARã‚’æ–°ã—ã„å½¢å¼ã«å¤‰æ›
                                if current_data_type.startswith("VARCHAR"):
                                    current_data_type = "VARCHAR(16777216)"
                                else:
                                    current_data_type = data_type_options[0]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’è¨­å®š
                            
                            data_type = st.selectbox(
                                f"ãƒ‡ãƒ¼ã‚¿å‹_{i}",
                                options=data_type_options,
                                index=data_type_options.index(current_data_type),
                                key=f"data_type_{i}",
                                label_visibility="collapsed"
                            )
                        
                        with col3:
                            st.text(schema_item['sample_data'][:20] + "..." if len(schema_item['sample_data']) > 20 else schema_item['sample_data'])
                        
                        with col4:
                            # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ï¼ˆæ–‡å­—åˆ—ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã‚‹å ´åˆã®è­¦å‘Šãªã©ï¼‰
                            error_msg = ""
                            if data_type.startswith("NUMBER") or data_type == "FLOAT":
                                try:
                                    pd.to_numeric(df[schema_item['column_name']], errors='raise')
                                except:
                                    error_msg = "âš ï¸"
                            st.text(error_msg)
                        
                        updated_schema.append({
                            'column_name': column_name,
                            'data_type': data_type,
                            'sample_data': schema_item['sample_data']
                        })
                    
                    # æ›´æ–°ã•ã‚ŒãŸã‚¹ã‚­ãƒ¼ãƒã‚’ä¿å­˜
                    st.session_state.inferred_schema = updated_schema
                
                # Step 4: SQL ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                st.subheader("ğŸ“ ç”Ÿæˆã•ã‚Œã‚‹SQL")
                create_sql = create_table_sql(table_name, st.session_state.inferred_schema)
                st.code(create_sql, language="sql")
                
                # Step 5: ä¿å­˜å®Ÿè¡Œ
                st.subheader("ğŸ’¾ ãƒ†ãƒ¼ãƒ–ãƒ«ä¿å­˜")
                col1, col2 = st.columns([1, 1])
                
                with col1:
                    if st.button("ğŸš€ ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä¿å­˜", type="primary", use_container_width=True):
                        try:
                            with st.spinner("ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆä¸­..."):
                                # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
                                session.sql(create_sql).collect()
                                
                                # ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥ç”¨ã®Snowparkãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
                                snowpark_df = session.create_dataframe(df)
                                
                                # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«ã«æŒ¿å…¥ï¼ˆé¸æŠã•ã‚ŒãŸã‚¹ã‚­ãƒ¼ãƒã«ä¿å­˜ï¼‰
                                current_schema = get_current_data_schema()
                                full_table_name = f"{current_schema}.{table_name}"
                                snowpark_df.write.mode("overwrite").save_as_table(full_table_name)
                                
                            st.success(f"âœ… ãƒ†ãƒ¼ãƒ–ãƒ« '{table_name}' ãŒæ­£å¸¸ã«ä½œæˆã•ã‚Œã¾ã—ãŸï¼")
                            st.balloons()
                            
                            # çµæœç¢ºèª
                            result_df = session.table(full_table_name).limit(5).to_pandas()
                            st.write("**ä¿å­˜ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ï¼ˆå…ˆé ­5è¡Œï¼‰:**")
                            st.dataframe(result_df, use_container_width=True)
                            
                        except Exception as e:
                            st.error(f"âŒ ãƒ†ãƒ¼ãƒ–ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
                
                with col2:
                    if st.button("ğŸ—‘ï¸ ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
                        st.session_state.current_df = None
                        st.session_state.inferred_schema = []
                        st.session_state.table_name = ""
                        st.rerun()

    except Exception as e:
        st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")

else:
    st.info("ğŸ‘† CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

st.markdown("---")
st.markdown("**ğŸ“Š Streamlitãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ—ãƒª | ãƒ‡ãƒ¼ã‚¿å–è¾¼ - Â©SnowflakeåˆåŒä¼šç¤¾**") 
